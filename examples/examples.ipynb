{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/repos/sik-llms/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/repos/sik-llms/.venv/lib/python3.13/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': 'What is the capital of France?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sik_llms import create_client, user_message, ChatChunkResponse\n",
    "\n",
    "client = create_client(\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "message = user_message(\"What is the capital of France?\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponseSummary(content='The capital of France is Paris.', total_input_tokens=14, total_output_tokens=7, total_input_cost=2.1e-06, total_output_cost=4.2e-06, duration_seconds=0.5634920597076416)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client(messages=[message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "async for response in client.run_async(messages=[message]):\n",
    "    if isinstance(response, ChatChunkResponse):\n",
    "        print(response.content, end=\"\")\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' total_input_tokens=14 total_output_tokens=7 total_input_cost=2.1e-06 total_output_cost=4.2e-06 duration_seconds=0.4606339931488037\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponseSummary(content=\"The capital of France is Paris. It's not only the capital city but also the largest city in France, known for its iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\", total_input_tokens=14, total_output_tokens=49, total_input_cost=4.2000000000000004e-05, total_output_cost=0.000735, duration_seconds=1.3953912258148193)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = create_client(\n",
    "    model_name='claude-3-7-sonnet-latest',\n",
    "    temperature=0.1,\n",
    ")\n",
    "response = client(messages=[user_message(\"What is the capital of France?\")])\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCallResponse(input_tokens=60, output_tokens=17, input_cost=9e-06, output_cost=1.0199999999999999e-05, duration_seconds=0.8786740303039551, function_call=FunctionCallResult(name='get_weather', arguments={'location': 'Paris, France'}, call_id='call_OakECL19U7xSzKN4gy4NXtZc'), message=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sik_llms import Function, Parameter, RegisteredClients\n",
    "\n",
    "weather_tool = Function(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the weather for a location.\",\n",
    "    parameters=[\n",
    "        Parameter(\n",
    "            name=\"location\",\n",
    "            type=\"string\",\n",
    "            required=True,\n",
    "            description=\"The city and country for weather info.\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "client = create_client(\n",
    "    client_type=RegisteredClients.OPENAI_FUNCTIONS,\n",
    "    model_name='gpt-4o-mini',\n",
    "    functions=[weather_tool],\n",
    ")\n",
    "\n",
    "message = user_message(\"What is the weather in Paris?\")\n",
    "response = await client.run_async(messages=[message])\n",
    "# or `response = client(messages=[message])` for synchronous execution\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCallResponse(input_tokens=394, output_tokens=40, input_cost=0.001182, output_cost=0.0006000000000000001, duration_seconds=1.7429931163787842, function_call=FunctionCallResult(name='get_weather', arguments={'location': 'Paris, France'}, call_id='toolu_011pXGg6U2QsLt2DCVtS36AE'), message=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sik_llms import (\n",
    "    create_client,\n",
    "    user_message,\n",
    "    Function,\n",
    "    Parameter,\n",
    "    RegisteredClients,\n",
    ")\n",
    "\n",
    "weather_tool = Function(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the weather for a location.\",\n",
    "    parameters=[\n",
    "        Parameter(\n",
    "            name=\"location\",\n",
    "            type=\"string\",\n",
    "            required=True,\n",
    "            description=\"The city and country for weather info.\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "client = create_client(\n",
    "    client_type=RegisteredClients.ANTHROPIC_FUNCTIONS,\n",
    "    model_name='claude-3-7-sonnet-latest',\n",
    "    functions=[weather_tool],\n",
    ")\n",
    "\n",
    "message = user_message(\"What is the weather in Paris?\")\n",
    "response = await client.run_async(messages=[message])\n",
    "# or `response = client(messages=[message])` for synchronous execution\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs via OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponseSummary(input_tokens=92, output_tokens=18, input_cost=1.38e-05, output_cost=1.08e-05, duration_seconds=1.2957699298858643, content=StructuredOutputResponse(parsed=CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob']), refusal=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from sik_llms import create_client, system_message, user_message\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "# Create an instance of the wrapper\n",
    "client = create_client(\n",
    "    model_name='gpt-4o-mini',\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "messages=[\n",
    "    system_message(\"Extract the event information.\"),\n",
    "    user_message(\"Alice and Bob are going to a science fair on Friday.\"),\n",
    "]\n",
    "response = client(messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning via OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step:\n",
      "\n",
      "1. First, calculate the multiplications:\n",
      "   - 3 * 4 = 12\n",
      "   - 5 * 6 = 30\n",
      "\n",
      "2. Now substitute these back into the expression:\n",
      "   1 + 2 + 12 + 30\n",
      "\n",
      "3. Finally, add them together:\n",
      "   - 1 + 2 = 3\n",
      "   - 3 + 12 = 15\n",
      "   - 15 + 30 = 45\n",
      "\n",
      "So, the answer is 45."
     ]
    }
   ],
   "source": [
    "from sik_llms import (\n",
    "    create_client,\n",
    "    user_message,\n",
    "    ChatChunkResponse,\n",
    "    ChatResponseSummary,\n",
    "    ReasoningEffort,\n",
    ")\n",
    "\n",
    "client = create_client(\n",
    "    model_name='o3-mini',\n",
    "    reasoning_effort=ReasoningEffort.MEDIUM,\n",
    ")\n",
    "messages=[user_message(\"What is 1 + 2 + (3 * 4) + (5 * 6)?\")]\n",
    "summary = None\n",
    "async for response in client.run_async(messages=messages):\n",
    "    if isinstance(response, ChatChunkResponse):\n",
    "        print(response.content, end=\"\")\n",
    "    elif isinstance(response, ChatResponseSummary):\n",
    "        summary = response\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected response type: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponseSummary(content=\"Let's break it down step by step:\\n\\n1. First, calculate the multiplications:\\n   - 3 * 4 = 12\\n   - 5 * 6 = 30\\n\\n2. Now substitute these back into the expression:\\n   1 + 2 + 12 + 30\\n\\n3. Finally, add them together:\\n   - 1 + 2 = 3\\n   - 3 + 12 = 15\\n   - 15 + 30 = 45\\n\\nSo, the answer is 45.\", total_input_tokens=28, total_output_tokens=111, total_input_cost=3.08e-05, total_output_cost=0.0004884, duration_seconds=1.6389861106872559)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning via Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll evaluate this expression step by step.\n",
      "\n",
      "1 + 2 + (3 * 4) + (5 * 6)\n",
      "\n",
      "First, I'll compute the parts in parentheses.\n",
      "(3 * 4) = 12\n",
      "(5 * 6) = 30\n",
      "\n",
      "So the expression becomes:\n",
      "1 + 2 + 12 + 30\n",
      "\n",
      "Now I'll add these numbers:\n",
      "1 + 2 = 3\n",
      "3 + 12 = 15\n",
      "15 + 30 = 45\n",
      "\n",
      "So the final result is 45.To solve this expression, I'll follow the order of operations:\n",
      "\n",
      "1 + 2 + (3 * 4) + (5 * 6)\n",
      "\n",
      "First, I'll evaluate the expressions in parentheses:\n",
      "(3 * 4) = 12\n",
      "(5 * 6) = 30\n",
      "\n",
      "Now I can add all terms:\n",
      "1 + 2 + 12 + 30 = 45\n",
      "\n",
      "The answer is 45."
     ]
    }
   ],
   "source": [
    "from sik_llms import (\n",
    "    create_client,\n",
    "    user_message,\n",
    "    ChatChunkResponse,\n",
    "    ChatResponseSummary,\n",
    "    ReasoningEffort,\n",
    ")\n",
    "\n",
    "client = create_client(\n",
    "    model_name='claude-3-7-sonnet-latest',\n",
    "    reasoning_effort=ReasoningEffort.MEDIUM,\n",
    ")\n",
    "messages=[user_message(\"What is 1 + 2 + (3 * 4) + (5 * 6)?\")]\n",
    "summary = None\n",
    "async for response in client.run_async(messages=messages):\n",
    "    if isinstance(response, ChatChunkResponse):\n",
    "        print(response.content, end=\"\")\n",
    "    elif isinstance(response, ChatResponseSummary):\n",
    "        summary = response\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected response type: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
