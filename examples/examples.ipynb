{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/repos/sik-llms/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/repos/sik-llms/.venv/lib/python3.13/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': 'What is the capital of France?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sik_llms import create_client, user_message, ChatChunkResponse\n",
    "\n",
    "model = create_client(\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "message = user_message(\"What is the capital of France?\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponseSummary(content='The capital of France is Paris.', total_input_tokens=14, total_output_tokens=7, total_input_cost=2.1e-06, total_output_cost=4.2e-06, duration_seconds=0.5634920597076416)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(messages=[message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "async for response in model.run_async(messages=[message]):\n",
    "    if isinstance(response, ChatChunkResponse):\n",
    "        print(response.content, end=\"\")\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' total_input_tokens=14 total_output_tokens=7 total_input_cost=2.1e-06 total_output_cost=4.2e-06 duration_seconds=0.4606339931488037\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCallResponse(function_call=FunctionCallResult(name='get_weather', arguments={'location': 'Paris, France'}, call_id='call_FwCxd4Wucp2mgWYwVrJ92L6d'), input_tokens=60, output_tokens=17, input_cost=9e-06, output_cost=1.0199999999999999e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sik_llms import Function, Parameter, RegisteredClients\n",
    "\n",
    "weather_tool = Function(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the weather for a location.\",\n",
    "    parameters=[\n",
    "        Parameter(\n",
    "            name=\"location\",\n",
    "            type=\"string\",\n",
    "            required=True,\n",
    "            description=\"The city and country for weather info.\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "client = create_client(\n",
    "    client_type=RegisteredClients.OPENAI_FUNCTIONS,\n",
    "    model_name='gpt-4o-mini',\n",
    "    functions=[weather_tool],\n",
    ")\n",
    "\n",
    "message = user_message(\"What is the weather in Paris?\")\n",
    "response = client(messages=[message])\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
